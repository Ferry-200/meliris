# Meliris: An Intelligent System for LRC Enhancement based on Vocal Detection

## 模型方案设计

### 一、总体思路

本项目旨在构建一个**结合人声检测与演唱者区分**的 LRC 歌词自动优化系统，
目标是在较小的训练数据量（500 首音乐）下
实现高精度、可解释、具备实时性的预测结果。

在前期实验中，LSTM 模型已经能较好地捕捉人声时序规律，
但在遇到复杂伴奏、间奏或歌声变化时仍存在以下问题：

* 模型对音色和节奏变化敏感度不足；
* 预测稳定性偏低；
* 对人声与间奏的置信度差距有限；
* 模型在噪声和多乐器干扰下容易误判。

### 二、CNN + LSTM 结构

#### 2.1 设计思路

* **CNN（卷积神经网络）** 用于从音频的 Mel 频谱中提取局部时频模式，能捕捉到：

  * 不同频段的谐波结构；
  * 乐器与人声的频谱差异；
  * 人声的共振特征与能量集中区。

* **LSTM（长短期记忆网络）** 用于处理 CNN 输出的时间序列特征，
  建模音乐在时间维度上的依赖关系，如：

  * 人声音节之间的持续与间断；
  * 歌曲结构变化；
  * 间奏的节奏规律。

CNN 提供高层局部特征，LSTM 建立时间关系，
两者结合能够让模型兼具“听觉细节”与“时序记忆”。

#### 2.2 模型结构示意（文本描述）

```
输入：Mel 频谱 (T × F)
 ↓
2D 卷积层（Conv2D + ReLU + Pooling）
 ↓
特征展平 (Flatten)
 ↓
LSTM 层
 ↓
时间分布全连接层（TimeDistributed Dense）
 ↓
Sigmoid 输出（预测每帧为人声的概率）
```

#### 2.3 优点分析

| 特点 | 优势 |
| ---- | ---- |
| CNN 负责局部频谱提取 | 减少频率噪声影响，捕捉音色模式 |
| LSTM 负责时间建模 | 保留上下文语义，处理延续性人声 |
| 结构轻量 | 可在 CPU 或移动设备上运行 |
| 对训练量要求低 | 适合 500 首以内数据集   |

## 最终研究路线：人声活动检测中的标签质量与任务优化分析

### 阶段一：基线模型与弱监督性能评估 (LRC Baseline)

**目标：** 建立基于传统、粗糙文本标注的性能基线（Performance Floor），为后续改进提供严格的对比依据。

| 元素 | 描述 |
| :--- | :--- |
| **标签来源** | **LRC 文本时间戳**（通常是反转后进行加权）。 |
| **监督性质** | 弱监督（Weak Supervision）。 |
| **模型架构** | **单任务：** CNN + LSTM + Sigmoid 输出。 |
| **训练挑战** | LRC 标注不准确，导致模型难以区分弱人声和乐器，边界模糊。 |
| **核心产出** | 模型的基线 F1-Score、Precision 和 Recall。 |

---

### 阶段二：标签优化与强监督单任务性能验证 (Optimized Single-Task)

**目标：** 通过引入专业 SVD 模型的判别能力，生成最高质量的二分类标签，验证标签质量提升对模型性能的巨大贡献，并建立最优单任务模型。

| 元素 | 描述 |
| :--- | :--- |
| **标签生成** | **创新点：** 使用 HT Demucs f.t. (v4) 分离的人声轨 $V$ 作为输入，利用**预训练 SVD 模型**（如 Silero VAD）进行推理，生成**高质量的二分类标签 $Y_{SVD}$**。 |
| **监督性质** | 强监督（Strong Supervision）。 |
| **模型架构** | **单任务：** 保持 **CNN + LSTM** 架构不变（只替换标签）。 |
| **训练优势** | 新标签 $Y_{SVD}$ 解决了小提琴混淆和弱人声边界不清晰的问题。 |
| **核心产出** | **性能对比：** 严格对比 F1-Score 相较于阶段一的提升幅度（预期是数量级提升）。**证明标签质量优于模型结构复杂度。** |

---

### 阶段三：多任务学习探索与边际效益分析 (MTL Enhancement)

**目标：** 在拥有高质量分类标签 $Y_{SVD}$ 的基础上，探索引入人声比例（Ratio）作为辅助任务是否能带来**额外的边际性能提升**，并分析 MTL 的必要性与成本。

| 元素 | 描述 |
| :--- | :--- |
| **任务设计** | **多任务：** 分类（人声/间奏） + 回归（人声占比 Ratio）。 |
| **模型架构** | **双头输出：** CNN + LSTM 共享编码器，分叉出分类头和回归头。 |
| **标签来源** | 1. **分类标签：** $Y_{SVD}$（来自 SVD/VAD 模型）。2. **回归标签：** $\text{Ratio} = V/(V+I)$（来自 Spleeter）。 |
| **损失函数** | **联合损失：** $L_{total} = \lambda_{1} L_{cls} + \lambda_{2} L_{reg}$。其中 $L_{reg}$ 应使用 **Loss Masking**（仅在有效人声区域计算回归误差）。 |
| **核心产出** | **必要性论证：** 比较 MTL 模型相较于阶段二单任务模型的 F1-Score 提升是否显著。若提升微小，则结论为“最优单任务模型在工程上更具优势”。 |

### 科学评估与最终总结

您的最终论文将围绕以下三个核心对比点展开：

1.  **标签质量对比：** 证明 $Y_{SVD}$ **显著优于** LRC 标签。
2.  **性能贡献对比：** 证明 **阶段二** 模型（强监督单任务）的性能 **远超** **阶段一** 模型（弱监督基线）。
3.  **任务优化对比：** 论证 **阶段三** 模型（MTL）相较于 **阶段二** 模型（最优单任务）的**边际效益**，得出关于模型复杂度与性能平衡的最终结论。